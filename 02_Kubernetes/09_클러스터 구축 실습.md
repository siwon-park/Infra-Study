![kubernets](https://user-images.githubusercontent.com/93081720/174333422-4e2f7a03-f585-4edf-884c-0af7fea7ac5d.png)

# 09_EC2 쿠버네티스 클러스터 구축 실습

직접 EC2에 쿠버네티스 클러스터를 구축해보자

※ 참조: https://dongle94.github.io/kubernetes/kubernetes-cluster-build/

<br>

## 1. 설치 및 사전 준비

### 1) EC2 환경 구성

#### (1) 마스터-워커 노드 IP 주소 확인

```bash
마스터: 172.26.8.229
워커: 172.26.0.105
```

<br>

#### (2) NTP 서버 동기화

`NTP(Network Time Protocol)`는 클러스터를 구축하면 각 노드들이 네트워크 통신을 하는데, 각 노드들의 시간이 맞지 않아 통신에 문제가 발생할 수도 있기 때문에 이러한 리스크를 없애기 위해 설정하였다. (굳이 실습만 진행할 거면 넘어가도 무방하다.)

```bash
$ sudo apt install ntp
```

- 마스터 노드 동작 확인

```bash
$ sudo service ntp reload
$ sudo ntpq -p
```

- 워커 노드 설정 변경
  - 워커 노드에도 ntp를 설치한다.
  - 단, 마스터 노드와 달리 워커 노드는 마스터 노드와 설정 동기화가 필요하다.

```bash
# 주석이 해제되어 있는 pool과 server를 주석 처리하고 마스터 노드의 IP를 추가함
$ sudo vi /etc/ntp.conf

server [마스터 노드 IP]

# 재시작 및 동기화 확인
$ sudo systemctl restart ntp
$ sudo ntpq -p
```

<br>

#### (3) 스왑 메모리 기능 off

쿠버네티스 클러스터는 스왑 메모리가 활성화 되어 있는 것을 허용하지 않는다. 마찬가지로 `kubeadm`이 스왑 메모리를 허용하지 않기 때문에 스왑 메모리를 설정한 적이 있다면 해제한다.

```bash
$ sudo swapoff -a
```

<br>

### 2) Docker 설치

[공식 문서](https://docs.docker.com/engine/install/ubuntu/) 참조

#### (1) 도커 데몬 컨테이너 런타임 변경

`cgroup`드라이버를 변경해준다. 자세한 내용은 [공식 문서](https://kubernetes.io/ko/docs/setup/production-environment/container-runtimes/)를 참조.

※ cgroup: `control group`을 의미하며, Linux에서 프로세스에 할당된 리소스를 관리, 제한하는데 사용되는 프로세스 그룹이다.

cgroup 드라이버를 변경을 해주는 이유는 기본적으로 두 개의 cgroup 드라이버(`cgroupfs`, `systemd`)가 있는데, `kubelet`의 기본 cgroup 드라이버는 `cgroupfs`인데, 리눅스 배포판의 init 시스템의 cgroup 드라이버는 `systemd`이다.

이렇게 서로 다른 두 개의 cgroup 드라이버를 사용하면, 해당 시스템은 두 개의 다른 cgroup 관리자를 갖는 것이다. 두 개의 cgroup 관리자를 사용하게 되면, 프로세스의 리소스를 관리함에 있어 혼란을 가져오기 때문에 불안정해질 수 밖에 없다.

따라서 이러한 불안정성을 없애기 위해서 cgroup 드라이버를 일치시키는 것이다.

- 도커 데몬의 컨테이너 런타임 환경을 `systemd`로 교체

```bash
$ sudo mkdir /etc/docker
$ sudo cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF
$ sudo mkdir -p /etc/systemd/system/docker.service.d
$ sudo systemctl daemon-reload
$ sudo systemctl restart docker
```

- 만약에 GPU 자원을 사용해야 하는 경우, 다음과 같이 추가 구성

```bash
$ sudo mkdir /etc/docker
$ cat <<EOF | sudo tee /etc/docker/daemon.json
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",

  "runtimes": {
        "nvidia": {
            "path": "nvidia-container-runtime",
            "runtimeArgs": []
        }
    },
  "default-runtime": "nvidia"
}
EOF
$ sudo systemctl daemon-reload
$ sudo systemctl restart docker
```

- cgroup 드라이버 변경 확인

```bash
$ sudo docker info | grep -i cgroup
```

![cgroup](https://github.com/siwon-park/Infra_Study/assets/93081720/f35d5acd-33d1-459e-9cba-fcee3706c286)

<br>

### 3) 쿠버네티스 Set Up (저장소 추가 및 Kubeadm 설치)

gpg 저장소를 추가하고, `kubeadm`을 설치할 수 있는 환경을 만들어 설치해준다. 역시 자세한 내용은 [공식문서](https://kubernetes.io/ko/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)를 참조.

#### (1) 패키지 리스트 업데이트

```bash
$ sudo apt-get update
$ sudo apt-get upgrade
```

<br>

#### (2) 데비안 기반 배포판 설치

```bash
$ sudo apt-get update
$ sudo apt-get install -y apt-transport-https ca-certificates curl
```

<br>

#### (3) 구글 클라우드 public signing key 다운로드

```bash
$ sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
```

<br>

#### (4) 쿠버네티스 apt 레포지토리 추가

```bash
echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
```

<br>

#### (5) apt 패키지 색인 업데이트 및 kubelet, kubeadm, kubectl 설치

`kubelet`, `kubeadm`, `kubectl` 설치 후 버전을 고정한다.

```bash
$ sudo apt-get update
$ sudo apt-get install -y kubelet kubeadm kubectl
$ sudo apt-mark hold kubelet kubeadm kubectl # 버전 고정
```

- 버전 확인

```bash
$ sudo kubeadm version
$ sudo kubelet --version
$ sudo kubectl version
```

<br>

### 4) 워커 노드 셋업

지금까지 진행한 것은 `마스터 노드`에 대한 것이었고, `워커 노드`에도 위와 같은 과정을 반복해준다.

워커 노드에 환경을 구성하지도 않고 쿠버네티스가 안 된다고 하면 곤란하다.

<br>

## 2. 클러스터 구축

- 마스터 노드 시작
  - 기본적으로 마스터 노드는 `kubeadm init <args>`를 통해 실행 가능하다.

※ 아직 해당 명령어를 입력하지는 말자. `Pod 네트워크`를 먼저 구성하는 것이 먼저다.

```bash
$ sudo kubeadm init <args> # agrg에는 여러 옵션을 주어서 마스터 노드를 시작할 수 있다
```

<br>

### 1) Pod 네트워크 설정

클러스터에서 Pod가 서로 통신할 수 있도록 `Pod 네트워크`라는 것을 설치, 설정해줘야 한다.

`kubeadm`을 통해서 만들어진 클러스터는 `CNI (Container Network Interface)`기반의 애드온이 필요하다.

쿠버네티스에서 기본적으로 제공해주는 `kubenet`이라는 네트워크 플러그인을 사용해도 되지만, 매우 기본적이고 간단한 기능만 제공하기 때문에, 크로스 노드 네트워킹이나 네트워크 정책과 같은 고급 기능은 구현되어 있지 않아 이런 기능들을 사용하기엔 부적합하다. 이러한 이유 때문에 `kubeadm`은 kubenet을 지원하지 않고 `CNI 기반의 네트워크`만 지원한다.

- `Calico`, `Flannel`, `Wave Net`, `Cilium` 등의 CNI 네트워크가 있고, 각 네트워크마다 차이점이 존재하므로 적절한 네트워크 플러그인을 선택하면 된다.
- 또한 각 네트워크 플러그인마다 사용하는 네트워크 대역이 다르기 때문에 이를 유의해야 한다. 변경이 가능하나 지정된 네트워크 대역 내에서만 변경할 수 있음을 유의하자.
  - `Calico`를 사용할 예정이면 `--pod-network-cidr=192.168.10.0/16`로 설정한다.
  - `Flannel`을 사용할 예정이면 `--pod-network-cidr=10.244.10.0/16` 로 설정한다.
  - `Wave Net`을 사용할 예정이면 `--pod-network-cidr=10.32.0.0/12` 로 설정한다.
  - `Cilium`을 사용할 예정이면 `--pod-network-cidr=10.128.0.0/9` 로 설정한다.

<br>

### 2) 마스터 노드 실행

사용할 Pod 네트워크를 선택했으면 `kubeadm init` 명령어를 통해 마스터 노드를 실행해보자.

※ 설정한 네트워크 플러그인의 IP는 기억을 해두자.

```bash
$ sudo kubeadm init --apiserver-advertise-address=<마스터 노드 ip 주소> --pod-network-cidr=192.168.10.0/16

# 예시(Calico 네트워크 플러그인 적용)
$ sudo kubeadm init --apiserver-advertise-address=172.26.8.229 --pod-network-cidr=192.168.10.0/16
```

- 실행에 성공하면 아래와 같은 메세지와 함께 마스터 노드가 정상적으로 실행되었음을 알 수 있다.

![kubeadm_init](https://github.com/siwon-park/Infra_Study/assets/93081720/fafb2ac8-b701-49b3-9cb6-55e95a9e692d)

<br>

### 3) config 디렉토리 생성

`kubeadm`을 실행했을 때 나오는 메세지를 그대로 붙여 넣어준다.

```bash
$ mkdir -p $HOME/.kube
$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
$ sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

<br>

### 4) 워커 노드 연결

마찬가지로 마스터 노드를 실행할 때 나왔던 메세지 중 마지막에 있는 부분을 복사하여 `워커 노드`에서 해당 명령어를 입력해준다.

마스터 노드와 워커 노드를 연결하는 과정이며, 토큰으로 암호화되어 연결하는 것이다.

```bash
$ sudo kubeadm join 172.26.8.229:6443 --token i53j5a.fc3jaqu22dq8l2ey --discovery-token-ca-cert-hash sha256:035a74d98cc8089d6c6ffd77318eb674f5bfa02c951b4c3b666eceb70ed961aa
```

#### (1) kubeadm join 에러 발생 시

분명히 마스터 노드에서 나온 join 토큰 값을 입력했는데, 다음과 같이 토큰 에러가 발생한다면

![kubeadm_token_error](https://github.com/siwon-park/Infra_Study/assets/93081720/ecbf4bbc-5b20-4f75-80d1-87c5d964b130)

`마스터 노드`에서 토큰 리스트를 출력해서 토큰을 삭제한 다음에, 재생성하여 연결하면 된다.

```bash
$ sudo kubeadm token list # 토큰 리스트 출력
$ sudo kubeadm token delete [토큰 코드] # 토큰 삭제
$ sudo kubeadm token create --print-join-command # 토큰 재생성 및 join 커맨드와 같이 출력
```

<br>

#### (2) 노드 간 연결 확인

마스터 노드에서 아래와 같은 명령어를 입력하여 노드가 제대로 연결되었는지 확인할 수 있다.

```bash
$ sudo kubectl get nodes
```

- 마스터 노드는 `control-plane`이라고 써 있는 것을 확인할 수 있다.

![kubectl_get_node](https://github.com/siwon-park/Infra_Study/assets/93081720/4914c343-b371-4728-8ab8-df441a29b876)

<br>

### 5) 네트워크 연결

노드 간 실시간 네트워크 통신을 할 수 있도록 네트워크를 설정, 연결해준다.

- Calico

```bash
$ curl https://raw.githubusercontent.com/projectcalico/calico/v3.25.1/manifests/calico.yaml -O

# 네트워크 대역을 Calico의 기본값인 192.168.0.0/16이 아니라, 192.168.10.0/24로 변경했을 시 설정
# sed -i -e 's?192.168.0.0/16?192.168.10.0/24?g' calico.yaml

$ kubectl apply -f calico.yaml
```

만약 Calico 네트워크의 연결 대역을 변경했다면  `sed -i -e 's?192.168.0.0/16?192.168.10.0/24?g' calico.yaml` 와 같이 설정한 calico의 pod 네트워크를 변경하고자 할 때, 위와 같은 명령어로 변경하거나 직접 파일에 들어가서 수정하면 된다.

#### (1) 네트워크 연결 확인

```bash
$ sudo kubectl get pods --namespace kube-system
```

- 정상적으로 네트워크 연결까지 되었다면 `READY` 항목에 `1/1`이라고 설정되어 있는 것을 볼 수 있다.

![network_setup_success](https://github.com/siwon-park/Infra_Study/assets/93081720/75f5b856-422d-4d57-8c25-0244bf676486)

<br>

### 6) 클러스터 구축 확인

마스터 노드에서 `sudo kubectl get nodes`을 입력했을 때, 아래 사진과 같이 클러스터로 연결된 노드들의 상태가 `Ready`로 되어 있다면, 정상적으로 클러스터가 구축된 것이다.

![k8s_cluster](https://github.com/siwon-park/Infra_Study/assets/93081720/9a51baa5-b8a4-444f-a23e-189088ba394c)

<br>

## 4. 쿠버네티스 오브젝트 실행



<br>

## 5. [심화] 프로젝트 배포